{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning - Practicum 5 - Naive Bayes Classifier\n",
    "\n",
    "**Topics covered**: Label Encoding, Naive Bayes Classifier Algorithm\n",
    "\n",
    "**Deliverables**:\n",
    "- Complete the tasks as detailed in this document.\n",
    "- You are not allowed to use any Machine Learning APIs for this practicum (NumPy and Pandas are allowed).\n",
    "\n",
    "**Objectives**:  \n",
    "Naive Bayes is a very simple classification algorithm that makes some strong assumptions about the independence of each input variable. Nevertheless, it has been shown to be effective in a large number of problem domains. In this chapter you will discover the Naive Bayes algorithm for categorical data. After reading this chapter you will know.\n",
    "- How to work with categorical data for Naive Bayes.\n",
    "- How to prepare the class and conditional probabilities for a Naive Bayes model.\n",
    "- How to use a learned Naive Bayes model to make predictions.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Dataset\n",
    "Run the following cell to load the dataset and import the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset describes two categorical input variables and a class variable that has two outputs:\n",
    "\n",
    "| Weather | Car     | Class     |\n",
    "|---------|---------|-----------|\n",
    "| sunny   | working | go-out    |\n",
    "| rainy   | broken  | go-out    |\n",
    "| sunny   | working | go-out    |\n",
    "| sunny   | working | go-out    |\n",
    "| sunny   | working | go-out    |\n",
    "| rainy   | broken  | stay-home |\n",
    "| rainy   | broken  | stay-home |\n",
    "| sunny   | working | stay-home |\n",
    "| sunny   | broken  | stay-home |\n",
    "| rainy   | broken  | stay-home |\n",
    "\n",
    "For the dataset above to be useful, we need to convert the categorical input variables to nominal data.\n",
    "\n",
    "Since each input has only two values and the output class variable has two values, we should convert each variable to binary based on the following representations:\n",
    "- Weather: sunny = 1, rainy = 0\n",
    "- Car: working = 1, broken = 0\n",
    "- Class: go-out = 1, stay-home = 0\n",
    "\n",
    "This is also known as label encoding.\n",
    "\n",
    "Write a function called `label_encoder` that takes in the dataset `df` as input and returns the encoded dataset `edf` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoder(df):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell. Your dataset should be restated as follows:\n",
    "\n",
    "| Weather \t| Car \t| Class |\n",
    "|:---------:|:-----:|:-----:|\n",
    "| 1 \t\t| 1 \t| 1     |\n",
    "| 0 \t\t| 0 \t| 1     |\n",
    "| 1 \t\t| 1 \t| 1     |\n",
    "| 1 \t\t| 1 \t| 1     |\n",
    "| 1 \t\t| 1 \t| 1     |\n",
    "| 0 \t\t| 0 \t| 0     |\n",
    "| 0 \t\t| 0 \t| 0     |\n",
    "| 1 \t\t| 1 \t| 0     |\n",
    "| 1 \t\t| 0 \t| 0     |\n",
    "| 0 \t\t| 0 \t| 0     |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = label_encoder(df)\n",
    "print(edf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Learn a Naive Bayes Model\n",
    "There are two types of quantities that need to be calculated from the dataset for the naive Bayes model:\n",
    "- Class Probabilities.\n",
    "- Conditional Probabilities.\n",
    "Let's start with the class probabilities.\n",
    "\n",
    "### 2.1 Calculate the Class Probabilities\n",
    "The dataset is a two class problem. We can calculate the class probabilities for classes 0 and 1 as follows:\n",
    "\n",
    "$$\n",
    "P(class = 1) = \\frac{count(class = 1)}{count(class = 0) + count(class = 1)} \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(class = 0) = \\frac{count(class = 0)}{count(class = 0) + count(class = 1)} \\\\\n",
    "$$\n",
    "\n",
    "Write a function `calc_class_prob` that takes in the encoded dataset `edf` as input and returns the probability of each class `class_prob` as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_class_prob(edf):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to store the class probabilities in the variable `cls_prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_prob = calc_class_prob(edf)\n",
    "print(cls_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculate the Conditional Probabilities\n",
    "The conditional probabilities are the probability of each input value given each class value. The conditional probabilities for the dataset can be calculated as follows:\n",
    "\n",
    "#### Weather Input Variable\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&P(weather = sunny|class = \\text{go-out}) = \\frac{count(weather = sunny \\wedge class = \\text{go-out})}{count(class = \\text{go-out})}\\\\\n",
    "&P(weather = rainy|class = \\text{go-out}) = \\frac{count(weather = rainy \\wedge class = \\text{go-out})}{count(class = \\text{go-out})}\\\\\n",
    "&P(weather = sunny|class = \\text{stay-home}) = \\frac{count(weather = sunny \\wedge class = \\text{stay-home})}{count(class = \\text{stay-home})}\\\\\n",
    "&P(weather = rainy|class = \\text{stay-home}) = \\frac{count(weather = rainy \\wedge class = \\text{stay-home})}{count(class = \\text{stay-home})}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Car Input Variable\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&P(car = working|class = \\text{go-out}) = \\frac{count(car = working \\wedge class = \\text{go-out})}{count(class = \\text{go-out})}\\\\\n",
    "&P(car = broken|class = \\text{go-out}) = \\frac{count(car = broken \\wedge class = \\text{go-out})}{count(class = \\text{go-out})}\\\\\n",
    "&P(car = working|class = \\text{stay-home}) = \\frac{count(car = working \\wedge class = \\text{stay-home})}{count(class = \\text{stay-home})}\\\\\n",
    "&P(car = broken|class = \\text{stay-home}) = \\frac{count(car = broken \\wedge class = \\text{stay-home})}{count(class = \\text{stay-home})}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Remember that the $\\wedge$ symbol is just a shorthand for conjunction (AND).\n",
    "\n",
    "Write a conditional probability function `condProb` that takes in the encoded_dataframe `edf`, input variable name as a string `i_name`, an input variable value `i_val`, and a class value `c` as parameters and returns the conditional probability `cond_prob`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cond_prob(edf, i_name, i_val, c):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, run the following cell, you should get:\n",
    "\n",
    "#### Weather Input Variable\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&P(weather = sunny|class = \\text{go-out}) = 0.8\\\\\n",
    "&P(weather = rainy|class = \\text{go-out}) = 0.2\\\\\n",
    "&P(weather = sunny|class = \\text{stay-home}) = 0.4\\\\\n",
    "&P(weather = rainy|class = \\text{stay-home}) = 0.6\n",
    "\\end{align} \n",
    "$$\n",
    "\n",
    "#### Car Input Variable\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&P(car = working|class = \\text{go-out}) = 0.8\\\\\n",
    "&P(car = broken|class = \\text{go-out}) = 0.2\\\\\n",
    "&P(car = working|class = \\text{stay-home}) = 0.2\\\\\n",
    "&P(car = broken|class = \\text{stay-home}) = 0.8\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weather Input Variable\")\n",
    "print(calc_cond_prob(edf,'Weather',1,1))\n",
    "print(calc_cond_prob(edf,'Weather',0,1))\n",
    "print(calc_cond_prob(edf,'Weather',1,0))\n",
    "print(calc_cond_prob(edf,'Weather',0,0))\n",
    "\n",
    "print(\"\\nCar Input Variable\")\n",
    "print(calc_cond_prob(edf,'Car',1,1))\n",
    "print(calc_cond_prob(edf,'Car',0,1))\n",
    "print(calc_cond_prob(edf,'Car',1,0))\n",
    "print(calc_cond_prob(edf,'Car',0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have everything we need to make predictions using the Naive Bayes model.\n",
    "\n",
    "## 3. Make Predictions with Naive Bayes\n",
    "We can make predictions using Bayes Theorem, defined and explained in the previous chapter.\n",
    "\n",
    "$$\n",
    "P(h|d) = \\frac{P(d|h) \\times P(h)}{P(d)}\n",
    "$$\n",
    "\n",
    "In fact, we don't need a probability to predict the most likely class for a new data instance. We only need the numerator and the class that gives the largest response, which will be the predicted output.\n",
    "\n",
    "$$\n",
    "MAP(h) = max(P(d|h) \\times P(h))\n",
    "$$\n",
    "\n",
    "Let's take the first record from our dataset and use our learned model to predict which class we think it belongs.\n",
    "\n",
    "First instance: \n",
    "$$\n",
    "\\begin{align}\n",
    "&weather = sunny,\\ &&car = working \\\\\n",
    "&or \\\\\n",
    "&weather = 1,\\ &&car = 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We plug the probabilities for our model in for both classes and calculate the response. Starting with the response for the output $\\text{go-out}$. We multiply the conditional probabilities together and multiply it by the probability of any instance belonging to the class.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{go-out}\\ =\\ &P(weather = sunny|class = \\text{go-out})\\ \\times \\\\\n",
    "&P(car = working|class = \\text{go-out})\\ \\times \\\\\n",
    "&P(class = \\text{go-out})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\text{go-out} = 0.8 \\times 0.8 \\times 0.5 \\\\\n",
    "&\\text{go-out} = 0.32\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "We can perform the same calculation for the stay-home case:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{stay-home} = &P(weather = sunny|class = \\text{stay-home}) \\times \\\\\n",
    "&P(car = working|class = \\text{stay-home}) \\times \\\\\n",
    "&P(class = \\text{stay-home})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\text{stay-home} = 0.4 \\times 0.2 \\times 0.5 \\\\\n",
    "&\\text{stay-home} = 0.04\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We can see that 0.32 is greater than 0.04, therefore we predict go-out for this instance, which is correct. We can repeat this operation for the entire dataset, as follows:\n",
    "\n",
    "|Weather|Car|Class|go-out?|stay-home?|Prediction|\n",
    "|-------|---|-----|-------|----------|----------|\n",
    "|sunny|working|go-out|0.32|0.04|go-out          |\n",
    "|rainy|broken|go-out|0.02|0.24|stay-home        |\n",
    "|sunny|working|go-out|0.32|0.04|go-out          |\n",
    "|sunny|working|go-out|0.32|0.04|go-out          |\n",
    "|sunny|working|go-out|0.32|0.04|go-out          |\n",
    "|rainy|broken|stay-home|0.02|0.24|stay-home     |\n",
    "|rainy|broken|stay-home|0.02|0.24|stay-home     |\n",
    "|sunny|working|stay-home|0.32|0.04|go-out       |\n",
    "|sunny|broken|stay-home|0.08|0.16|stay-home     |\n",
    "|rainy|broken|stay-home|0.02|0.24|stay-home     |\n",
    "\n",
    "Tying up everything, create a function `calc_predictions` that takes in the encoded dataset `edf` and returns the updated dataset containing both the responses of each class and the predicted class `pdf`, similar to that as shown in the table above. Your dataset should still be made up of numerical values.\n",
    "\n",
    "For your reference:\n",
    "- Weather: sunny = 1, rainy = 0\n",
    "- Car: working = 1, broken = 0\n",
    "- Class: go-out = 1, stay-home = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prediction(edf):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to update the dataset using the `prediction` function you have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = calc_prediction(edf)\n",
    "print(pdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `calc_accuracy`, that takes in the updated dataset `pdf` and compare the predicted class values with the actual class values and returns the accuracy as output `accuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(pdf):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we tally up the predictions compared to the actual class values, we should get an accuracy of 80%, which is excellent given that there are conflicting examples in the dataset. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calc_accuracy(pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Summary\n",
    "\n",
    "In this chapter you discovered exactly how to implement Naive Bayes from scratch. You learned:\n",
    "- How to work with categorical data with Naive Bayes.\n",
    "- How to calculate class probabilities from training data.\n",
    "- How to calculate conditional probabilities from training data.\n",
    "- How to use a learned Naive Bayes model to make predictions on new data.\n",
    "\n",
    "You now know how to implement Naive Bayes from scratch for categorical data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
